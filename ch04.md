## 리플리케이션
토픽 생성시 필수 옵션
- 토픽의 이름
- 파티션 수
- 리플리케이션 팩터 수

카프카는 리플리케이션 팩터라는 옵션을 이용해 관리자가 지정한 수 만큼의 리플리케이션을 가질 수 있기 때문에 N개의 리플리케이션이 있는 경우 N - 1까지의 브로커 장애가 발생해도 메시지 손실 없이 안정적으로 메시지를 주고받을 수 있다.
## 리더와 팔로워
- 리더 : 리플리케이션 중 하나가 선정되며, 모든 읽기와 쓰기는 그 리더를 통해서만 가능

프로듀서는 모든 리플리케이션에 메시지를 보내는 것이 아니라 리더에게만 전송하고 컨슈머도 리더로부터 메시지를 가저온다.

- 팔로워 : 리더에 문제가 발생학나 이슈가 있을 경우를 대비해 지속적으로 파티션의 리더가 새로운 메시지를 받았는지 확인하고, 새로운 메시지가 있다면 해당 메시지를 리더로부터 복제한다.
## 복제 유지와 커밋
- 리더와 팔로워는 ISR(InSyncReplica)라는 논리적 그룹으로 묶여있다.
- 해당 그룹 안에 속한 팔로워들만 새로운 리더의 자격을 가질 수 있다.
- 파티션의 리더는 팔로워들이 뒤처지지 않고 리플리케이션 동작을 잘하고 있는지 감시한다.
- 팔로워가 특정 주기의 시간만큼 복제 요청을 하지 않으면 리더는 해당 팔로워를 ISR 그룹에서 추방한다.(리더 자격 박탈)
- 토픽 상세보기 명령어를 통해 ISR 상태 육안으로 확인할 수 있다.
- 마지막 커밋 오프셋 위치는 **하이워터마크(high water mark)**라고 부른다.
- ISR 내에서 모든 팔로워의 복제가 완료되면, 리더는 커밋되었다는 표시를 하고 커밋되지 않은 메시지는 컨슈머가 읽어갈 수 없다. (메시지의 일관성 유지)
- /data/kafka-logs/replication-offset0checkpoint라는 파일에 마지막 커밋 오프셋 위치를 저장한다.
ex) peter-test01 0 1 -> 0은 파티션 번호, 1은 커밋된 오프셋 번호
## 리더와 팔로워의 단계별 리플리케이션 동작
- 동작과정
1. 프로듀서가 메시지를 전송하여 리더만 메시지를 저장한다.
2. 팔로워들은 리더에게 0번 오프셋 머시지 가져오기(fetch) 요청을 보낸 후 새로운 메시지가 있다는 사실을 인지하고 메시지를 리플리케이션한다. 이때 리더는 리플리케이션 동작의 성공 여부를 알지 못한다. (ACK를 리턴하지 않기 때문에)
3. 리더는 1번 오프셋 위치에 두 번째 새로운 메시지를 프로듀서로부터 받아 저장한다.
4. 팔로워들은 리더에게 1번 오프셋에 대한 리플리케이션을 요청
5. 리더는 팔로워들의 0번 오프셋 리플리케이션 동작이 성공했음을 인지하고, 오프셋 0에 커밋 표시를 한후 하이워터마크를 증가시킨다.
(팔로워가 0번 오프셋에 대한 리플리케이션을 실패하면 1번이 아닌 0번 오프셋에 대한 리플리케이션 요청을 보낸다.)
6. 리더는 팔로워들에게 0번 오프셋 메시지가 커밋되었다는 내용도 함께 전달한다.
7. 팔로워도 0번 오프셋에 대한 커밋을 표시하고 1번 오프셋 메시지를 리플리케이션한다.
8. 이 과정을 반복하며 리더와 팔로워 간 메시지의 최신 상태를 유지

→ ACK 통신을 제외하여 카프카의 리더는 메시지를 주고받는 기능에 더욱 집중
→ ACK 통신을 제외했음에도 팔로워와 리더 간의 리플리케이션 동작이 매우 빠르면서도 신뢰할 수 있다.
→ 리더가 푸시하는 방식이 아니라 팔로워들이 풀하는 방식으로 리더의 부하를 줄여준다.
## 리더에포크와 복구
- 리더에포크 : 카프카의 파티션들이 복구 동작을 할 때 메시지의 일관성을 유지하기 위한 용도로 이용
- 리더에포크 정보는 리플리캐아션 프로토콜에 의해 전파되고, 새로운 리더가 변경된 후 변경된 리더에 대한 정보는 팔로워에게 전달된다.
![](https://velog.velcdn.com/images/dmg919/post/07152d0d-8e0e-49f0-b1a1-6833638ca5bb/image.png)
그림 출처: https://dlgldgldgld.github.io/kafka/kafka-detail-impl/

팔로워는 2번 오프셋인 message2 메시지까지 리플리케이션을 완료했지만, 아직 리더로부터 하이워터마크를 2로 올리는 내용은 전달받지 못한 상태에서 팔로워가 다운된다.
- 리더에포크를 사용하지 않았을 때
팔로워는 자신이 갖고 있는 메시지들 중에서 자신의 워터마크보다 높은 메시지들은 신뢰할 수 없는 메시지로 판단하고 삭제한다. 1번 오프셋의 message2는 삭제된다.

팔로워는 리더에게 1번 오프셋의 새로운 메시지에 대한 가져오기 요청을 보낸다. 이 순간 리더였던 브로커가 예상치 못한 장애로 다운되어 남아있던 팔로워가 새로운 리더가 된다.
기존의 리더는 1번 오프셋의 message2를 갖고 있었지만 뉴 리더는 message2를 갖고 있지 않다.
![](https://velog.velcdn.com/images/dmg919/post/ec81b8e0-5d59-46a7-8053-5e55693a5786/image.png)
출처 : https://dlgldgldgld.github.io/kafka/kafka-detail-impl/

- 리더 에포크를 사용할 때
하이워터마크보다 앞에 있는 메시지를 무조건 삭제하지 않고 리더에게 리더에포크 요청을 보낸다.
1. 요청을 받은 리더는 리더에포크의 응답으로 1번 오프셋의 message2까지라고 팔로워에게 보낸다.
2. 팔로워는 자신의 하이워터마크보다 높은 1번 오프셋의 message2를 삭제하지 않고 리더의 응답을 확인한 후 message2까지 자신의 워터마크를 상향 조정한다.

따라서 메시지 손실을 방지할 수 있었다.
뉴리더가 자신이 팔로워일 때의 하이워터마크와 뉴리더일 때의 하이워터마크를 알고있다.
팔로워는 유효하지 않은 오프셋은 삭제한다.

## 컨트롤러
- 카프카 클러스터 중 하나의 브로커가 컨트롤러 역할(파티션의 ISR 리스트 중에서 리더를 선출)
- ISR 리스트 정보는 가용성 보장을 위해 주키퍼에 저장되어 있다.
- 컨트롤러는 새 리더를 선출하고 주키퍼에 기록하며, 변경된 정보를 모든 브로커에게 전달한다.
- 리더 선출 과정(예기치 않은 장애 발생)
![](https://velog.velcdn.com/images/dmg919/post/d8e761bc-0f72-482b-9df2-9c91dd25f9a4/image.png)

출처 : https://hoing.io/archives/57594

  1. 파티션 0번의 리더가 있는 브로커 1번이 예기치 않게 다운된다.
  2. 주키퍼는 1번 브로커와 연결이 끊어진 후, 0번 파티션의 ISR에서 변화가 생겼음을 감지한다.
  3. 컨트롤러는 주키퍼 위치를 통해 0번 파티션에 변화가 생긴 것을 감지하고, 해당 파티션 ISR 중 3번을 새로운 리더로 선출한다.
  4. 컨트롤러는 0번의 파티션의 새로운 리더가 3이라는 정보를 주키퍼에 기록한다.
  5. 이렇게 갱신된 정보는 현재 활성화 상태인 모든 브로커에게 전파된다.
---
- 제어된 종료 과정에서 리더 선출 과정
![](https://velog.velcdn.com/images/dmg919/post/6734a0a7-4913-4ca2-ae62-e201d9ed8cf6/image.png)

출처 : https://hoing.io/archives/57594

  1. 관리자가 브로커 종료 명령어를 실행하고, SIG_TERM신호가 브로커에게 전달
  2. SIG_TERM 신호를 받은 브로커는 컨트롤러에게 알린다.
  3. 컨트롤러는 리더 선출 작업을 진행하고, 해당 정보를 주키퍼에 기록한다.
  4. 컨트롤러는 새로운 리더 정보를 다른 브로커들에게 전송
  5. 컨트롤러는 종료 요청을 보낸 브로커에게 정상 종료한다는 응답을 보낸다.
  6. 응답을 받은 브로커는 캐시에 있는 내용을 디스크에 저장하고 종료
- 제어된 종료와 갑작스러운 종료의 차이는? 다운타임(downtime)
제어된 종료를 사용하면 브로커가 종료되기 전에 컨트롤러가 미리 리더 선출 작업을 진행하기에 내부적으로 파티션들의 다운타임을 최소화할 수 있다.
## 로그(로그 세그먼트)
토픽으로 들어오는 메시지는 세그먼트라는 파일에 저장.
메시지의 내용, 메시지의 키, 밸류, 오프셋, 메시지 크기 같은 정보가 저장되며, 로그 세그먼트 파일들은 브로커의 로컬 디스크에 보관된다.
- 로그 세그먼트의 최대 크기는 1GB가 기본값
롤링 전략 : 로그 세그먼트의 크기가 1GB에 도달하면 해당 세그먼트 파일을 클로즈하고, 새로운 로그 세그먼트를 생성하는 방식
- 로그 세그먼트를 관리하는 방법
  - 로그 세그먼트 삭제
  server.properties에서 log.cleanup.policy가 delete로 명시되어야한다. 해당 값은 기본값으로 적용된다.
  retention.ms=0 : 로그 세그먼트 보관 시간이 0보다 크면 삭제(0보다 클 수밖에 없으므로 저장된 메시지는 삭제된다.)
  카프카의 기본값은 5분 주기로 로그 세그먼트 파일을 체크하면서 삭제 작업을 수행한다.
  
      로그 세그먼트 파일명 생성 규칙 : 0001.log, 1은 오프셋 번호 
- 로그 세그먼트 컴팩션
컴팩션은 로그를 삭제하지 않고 컴팩션하여 보관
  - 로그 컴팩션은 기본적으로 로컬디스크에 저장되어 있는 세그먼트를 대상으로 실행되는데, 현재 활성화된 세그먼트는 제외하고 나머지 세그먼트들을 대상으로 컴팩션이 실행된다.
  - 카프카에서 로그 세그먼트를 컴팩션하면 메시지의 키값을 기준으로 마지막의 데이터만 보관하게 된다.
  - __consumer_offset토픽 : 키(컨슈머 그룹명, 토픽명)와 밸류(오프셋 커밋 정보) 형태로 메시지가 저장
  - 로그 컴팩션 동작이 일어나면 컨슈머 그룹은 항상 마지막으로 커밋된 오프셋 정보가 중요하므로, 과거에 커밋된 정보들은 삭제한다.
  - 현재의 구매 현황 상태를 보여주는 시스템에서 고유한 사용자 아이디가 메시지의 키값이고, 현재의 구매 상태 정보가 메시지의 밸류값이다. 
  주문완료 -> 배송준비 -> 배송 중 -> 배송 완료 4단계
  구매한 사용자 아이디를 기준으로 최종 상태만 사용자에게 노출하면되므로, 카프카의 로그 컴팩션 기능을 활용할 수 있다.
  - 프로듀서가 카프카로 메시지를 전송할 때 메시지의 키(선택)와 밸류(필수)를 같이 전송한다. 로그 컴팩션 기능을 사용하고자 한다면 키도 필숫값으로 전송해야 한다.
  - 로그 컴팩션 예시
![](https://velog.velcdn.com/images/dmg919/post/a6a034e2-5b02-4c0a-9cf9-6d3a6e245d43/image.png)

  출처 : https://kafka.apache.org/documentation/#compaction

  - 로그 컴팩션의 장점 : 빠른 장애 복구, 전체 로그를 복구하지 않고, 메시지의 키를 기준으로 최신의 상태만 복구하여 복구 시간을 줄일 수 있다.
  - 키값을 기준으로 최종값만 필요한 워크로드에 적용하는 것이 바람직하다.
  - 로그 컴팩션 작업이 실행되는 동안 브로커의 과도한 입출력 부하가 발생할 수 있으니 반드시 브로커의 리소스 모니터링도 병행하여 로그 컴팩션을 사용하는 것을 권장
